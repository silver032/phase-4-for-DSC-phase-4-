{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcee967-282a-42f4-b823-807ff14c20eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (552744237.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Creating a machine learning model to predict and reduce waste in the hospitality industry involves several steps. Here's a detailed workflow:\u001b[0m\n\u001b[1;37m                                                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Creating a machine learning model to predict and reduce waste in the hospitality industry involves several steps. Here's a detailed workflow:\n",
    "\n",
    "1. Data Collection and Preparation\n",
    "Identify Data Sources: Gather data from various sources such as inventory records, sales data, purchase orders, and waste logs.\n",
    "Data Integration: Combine data from different sources into a unified format.\n",
    "Data Cleaning: Handle missing values, outliers, and inconsistencies in the data. <->\n",
    "Feature Engineering: Create relevant features from the raw data, such as average daily usage, seasonal variations, and supplier reliability.\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "Descriptive Statistics: Compute basic statistics to understand the distribution and central tendencies of the data.\n",
    "Visualization: Use plots (e.g., histograms, scatter plots, heatmaps) to identify patterns, correlations, and trends.\n",
    "3. Model Selection\n",
    "Choose Algorithms: Select appropriate machine learning algorithms (e.g., Linear Regression, Decision Trees, Random Forest, Gradient Boosting, etc.).\n",
    "Baseline Model: Develop a simple baseline model to set a performance benchmark.\n",
    "4. Model Training and Validation\n",
    "Split Data: Divide the data into training and testing sets (e.g., 80% training, 20% testing).\n",
    "Train Models: Train multiple models using the training data.\n",
    "Hyperparameter Tuning: Optimize model parameters using techniques like grid search or random search.\n",
    "Cross-Validation: Use cross-validation to assess model performance and prevent overfitting.\n",
    "5. Model Evaluation\n",
    "Performance Metrics: Evaluate models using relevant metrics (e.g., Mean Absolute Error, Mean Squared Error, R-squared).\n",
    "Compare Models: Compare the performance of different models and select the best one.\n",
    "6. Model Deployment\n",
    "Integration: Integrate the selected model into the inventory management system.\n",
    "APIs: Develop APIs to allow the system to interact with the model and make predictions in real-time.\n",
    "User Interface: Update the user interface to display predictions and recommendations for reducing waste.\n",
    "7. Monitoring and Maintenance\n",
    "Track Performance: Continuously monitor the model's performance and make adjustments as needed.\n",
    "Regular Updates: Retrain the model periodically with new data to maintain accuracy and relevance.\n",
    "Feedback Loop: Implement a feedback loop to gather user input and improve the system over time.\n",
    "8. Documentation and Training\n",
    "Documentation: Create comprehensive documentation for the system, including setup, usage, and troubleshooting guides.\n",
    "Training: Provide training sessions for staff to ensure they can effectively use the new system.\n",
    "By following this workflow, you can develop a robust machine-learning model to predict and reduce waste in the hospitality industry, leading to cost savings and more sustainable operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2da0834-be32-40af-89c7-76b0443ba4b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/SalesKaggle3.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load data from the uploaded CSV file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/SalesKaggle3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal Data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/SalesKaggle3.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from the uploaded CSV file\n",
    "file_path = '/mnt/data/SalesKaggle3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Original Data:\\n\", data.head())\n",
    "\n",
    "# Data Cleaning\n",
    "# Handling missing values\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "data.dropna(inplace=True)  # Drop any remaining NaN values\n",
    "\n",
    "# Removing outliers (example using z-score method)\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
    "data = data[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Feature Engineering\n",
    "# Example: Creating new features such as average daily usage, seasonal variations, and supplier reliability\n",
    "\n",
    "# Since we don't have dates, we'll create a dummy 'date' column based on 'ReleaseYear'\n",
    "data['date'] = pd.to_datetime(data['ReleaseYear'], format='%Y')\n",
    "\n",
    "# Average Daily Usage (dummy example since actual usage data isn't available)\n",
    "data['daily_usage'] = data['ItemCount'] / 365  # Assuming item count spread over a year\n",
    "\n",
    "# Seasonal Variations (Example: Extracting month as a feature)\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "# Supplier Reliability (Example: Counting orders per marketing type as a proxy)\n",
    "marketing_reliability = data.groupby('MarketingType')['Order'].count().reset_index()\n",
    "marketing_reliability.columns = ['MarketingType', 'order_count']\n",
    "data = pd.merge(data, marketing_reliability, on='MarketingType')\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "print(\"Prepared Data:\\n\", data.head())\n",
    "\n",
    "# Save the cleaned and prepared data to a new CSV file\n",
    "output_file_path = '/mnt/data/prepared_sales_data.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"Prepared data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522c7af5-21dd-4014-a31c-e724e4dd7a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      6  Historical      115883       1.0        1.0             D   \n",
      "4      7  Historical      863939       1.0        1.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              4                 1        334011.0    100.00         2006   \n",
      "4              2                 1       1287938.0    121.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice  \n",
      "0          8         28.97        31.84  \n",
      "1         39          0.00        15.54  \n",
      "2         34         30.19        27.97  \n",
      "3         20        133.93        83.15  \n",
      "4         28          4.00        23.99  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_18716\\1688423829.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      8  Historical      214948       0.0        0.0             D   \n",
      "4      9  Historical      484059       0.0        0.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              0                 0       1783153.0    132.00         2011   \n",
      "4             13                 1       2314801.0     95.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice       date  daily_usage  month  \\\n",
      "0          8         28.97        31.84 2015-01-01     0.021918      1   \n",
      "1         39          0.00        15.54 2005-01-01     0.106849      1   \n",
      "2         34         30.19        27.97 2013-01-01     0.093151      1   \n",
      "3         33        138.98        13.64 2011-01-01     0.090411      1   \n",
      "4         33         90.77        46.49 2010-01-01     0.090411      1   \n",
      "\n",
      "   order_count  \n",
      "0        78961  \n",
      "1        78961  \n",
      "2        78961  \n",
      "3        78961  \n",
      "4        78961  \n",
      "Prepared data saved to C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load data from the local CSV file\n",
    "file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\SalesKaggle3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Original Data:\\n\", data.head())\n",
    "\n",
    "# Data Cleaning\n",
    "# Handling missing values\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "data.dropna(inplace=True)  # Drop any remaining NaN values\n",
    "\n",
    "# Removing outliers (example using z-score method)\n",
    "z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
    "data = data[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Feature Engineering\n",
    "# Example: Creating new features such as average daily usage, seasonal variations, and supplier reliability\n",
    "\n",
    "# Since we don't have dates, we'll create a dummy 'date' column based on 'ReleaseYear'\n",
    "data['date'] = pd.to_datetime(data['ReleaseYear'], format='%Y')\n",
    "\n",
    "# Average Daily Usage (dummy example since actual usage data isn't available)\n",
    "data['daily_usage'] = data['ItemCount'] / 365  # Assuming item count spread over a year\n",
    "\n",
    "# Seasonal Variations (Example: Extracting month as a feature)\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "# Supplier Reliability (Example: Counting orders per marketing type as a proxy)\n",
    "marketing_reliability = data.groupby('MarketingType')['Order'].count().reset_index()\n",
    "marketing_reliability.columns = ['MarketingType', 'order_count']\n",
    "data = pd.merge(data, marketing_reliability, on='MarketingType')\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "print(\"Prepared Data:\\n\", data.head())\n",
    "\n",
    "# Save the cleaned and prepared data to a new CSV file\n",
    "output_file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"Prepared data saved to {output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af18778a-be61-401e-8fa1-ae1093d7102b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      8  Historical      214948       0.0        0.0             D   \n",
      "4      9  Historical      484059       0.0        0.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              0                 0       1783153.0    132.00         2011   \n",
      "4             13                 1       2314801.0     95.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice        date  daily_usage  month  \\\n",
      "0          8         28.97        31.84  2015-01-01     0.021918      1   \n",
      "1         39          0.00        15.54  2005-01-01     0.106849      1   \n",
      "2         34         30.19        27.97  2013-01-01     0.093151      1   \n",
      "3         33        138.98        13.64  2011-01-01     0.090411      1   \n",
      "4         33         90.77        46.49  2010-01-01     0.090411      1   \n",
      "\n",
      "   order_count  \n",
      "0        78961  \n",
      "1        78961  \n",
      "2        78961  \n",
      "3        78961  \n",
      "4        78961  \n",
      "\n",
      "Descriptive Statistics:\n",
      "                Order    SKU_number  SoldFlag  SoldCount  ReleaseNumber  \\\n",
      "count  169374.000000  1.693740e+05  169374.0   169374.0  169374.000000   \n",
      "mean   112089.790694  7.932180e+05       0.0        0.0       3.129565   \n",
      "std     58690.905643  7.458508e+05       0.0        0.0       3.033849   \n",
      "min         2.000000  5.000100e+04       0.0        0.0       0.000000   \n",
      "25%     63814.250000  2.202690e+05       0.0        0.0       1.000000   \n",
      "50%    115982.500000  6.097090e+05       0.0        0.0       2.000000   \n",
      "75%    162457.750000  8.927660e+05       0.0        0.0       5.000000   \n",
      "max    208027.000000  3.471271e+06       0.0        0.0      15.000000   \n",
      "\n",
      "       New_Release_Flag  StrengthFactor       PriceReg    ReleaseYear  \\\n",
      "count     169374.000000    1.693740e+05  169374.000000  169374.000000   \n",
      "mean           0.636686    9.878815e+05      86.238418    2006.485612   \n",
      "std            0.480956    1.120475e+06      62.713925       5.850901   \n",
      "min            0.000000    6.275000e+00       0.000000    1979.000000   \n",
      "25%            0.000000    1.670326e+05      41.950000    2004.000000   \n",
      "50%            1.000000    5.840489e+05      68.000000    2007.000000   \n",
      "75%            1.000000    1.376105e+06     112.900000    2011.000000   \n",
      "max            1.000000    5.683273e+06     351.000000    2018.000000   \n",
      "\n",
      "           ItemCount   LowUserPrice    LowNetPrice    daily_usage     month  \\\n",
      "count  169374.000000  169374.000000  169374.000000  169374.000000  169374.0   \n",
      "mean       38.343175      27.253304      42.260128       0.105050       1.0   \n",
      "std        24.579191      33.312969      36.935653       0.067340       0.0   \n",
      "min         0.000000       0.000000       0.000000       0.000000       1.0   \n",
      "25%        21.000000       4.770000      17.960000       0.057534       1.0   \n",
      "50%        31.000000      14.580000      33.940000       0.084932       1.0   \n",
      "75%        48.000000      35.990000      54.320000       0.131507       1.0   \n",
      "max       154.000000     238.070000     432.340000       0.421918       1.0   \n",
      "\n",
      "         order_count  \n",
      "count  169374.000000  \n",
      "mean    85074.155951  \n",
      "std      5712.913352  \n",
      "min     78961.000000  \n",
      "25%     78961.000000  \n",
      "50%     90413.000000  \n",
      "75%     90413.000000  \n",
      "max     90413.000000  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Historical'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDescriptive Statistics:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Correlation Matrix\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCorrelation Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, corr_matrix)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Histograms\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Historical'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the cleaned and prepared data\n",
    "file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Prepared Data:\\n\", data.head())\n",
    "\n",
    "# Descriptive Statistics\n",
    "print(\"\\nDescriptive Statistics:\\n\", data.describe())\n",
    "\n",
    "# Correlation Matrix\n",
    "corr_matrix = data.corr()\n",
    "print(\"\\nCorrelation Matrix:\\n\", corr_matrix)\n",
    "\n",
    "# Visualization\n",
    "# Histograms\n",
    "data.hist(figsize=(15, 10))\n",
    "plt.suptitle('Histograms of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "sns.pairplot(data.select_dtypes(include=[np.number]))\n",
    "plt.suptitle('Scatter Plot of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for detecting outliers in numerical columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "data.select_dtypes(include=[np.number]).boxplot()\n",
    "plt.title('Boxplot of Numerical Features')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of categorical features\n",
    "categorical_columns = data.select_dtypes(include=[object]).columns\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data[col])\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54289071-f6de-44c0-a6ab-615e5ea74a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      8  Historical      214948       0.0        0.0             D   \n",
      "4      9  Historical      484059       0.0        0.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              0                 0       1783153.0    132.00         2011   \n",
      "4             13                 1       2314801.0     95.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice        date  daily_usage  month  \\\n",
      "0          8         28.97        31.84  2015-01-01     0.021918      1   \n",
      "1         39          0.00        15.54  2005-01-01     0.106849      1   \n",
      "2         34         30.19        27.97  2013-01-01     0.093151      1   \n",
      "3         33        138.98        13.64  2011-01-01     0.090411      1   \n",
      "4         33         90.77        46.49  2010-01-01     0.090411      1   \n",
      "\n",
      "   order_count  \n",
      "0        78961  \n",
      "1        78961  \n",
      "2        78961  \n",
      "3        78961  \n",
      "4        78961  \n",
      "\n",
      "Descriptive Statistics:\n",
      "                Order    SKU_number  SoldFlag  SoldCount  ReleaseNumber  \\\n",
      "count  169374.000000  1.693740e+05  169374.0   169374.0  169374.000000   \n",
      "mean   112089.790694  7.932180e+05       0.0        0.0       3.129565   \n",
      "std     58690.905643  7.458508e+05       0.0        0.0       3.033849   \n",
      "min         2.000000  5.000100e+04       0.0        0.0       0.000000   \n",
      "25%     63814.250000  2.202690e+05       0.0        0.0       1.000000   \n",
      "50%    115982.500000  6.097090e+05       0.0        0.0       2.000000   \n",
      "75%    162457.750000  8.927660e+05       0.0        0.0       5.000000   \n",
      "max    208027.000000  3.471271e+06       0.0        0.0      15.000000   \n",
      "\n",
      "       New_Release_Flag  StrengthFactor       PriceReg    ReleaseYear  \\\n",
      "count     169374.000000    1.693740e+05  169374.000000  169374.000000   \n",
      "mean           0.636686    9.878815e+05      86.238418    2006.485612   \n",
      "std            0.480956    1.120475e+06      62.713925       5.850901   \n",
      "min            0.000000    6.275000e+00       0.000000    1979.000000   \n",
      "25%            0.000000    1.670326e+05      41.950000    2004.000000   \n",
      "50%            1.000000    5.840489e+05      68.000000    2007.000000   \n",
      "75%            1.000000    1.376105e+06     112.900000    2011.000000   \n",
      "max            1.000000    5.683273e+06     351.000000    2018.000000   \n",
      "\n",
      "           ItemCount   LowUserPrice    LowNetPrice    daily_usage     month  \\\n",
      "count  169374.000000  169374.000000  169374.000000  169374.000000  169374.0   \n",
      "mean       38.343175      27.253304      42.260128       0.105050       1.0   \n",
      "std        24.579191      33.312969      36.935653       0.067340       0.0   \n",
      "min         0.000000       0.000000       0.000000       0.000000       1.0   \n",
      "25%        21.000000       4.770000      17.960000       0.057534       1.0   \n",
      "50%        31.000000      14.580000      33.940000       0.084932       1.0   \n",
      "75%        48.000000      35.990000      54.320000       0.131507       1.0   \n",
      "max       154.000000     238.070000     432.340000       0.421918       1.0   \n",
      "\n",
      "         order_count  \n",
      "count  169374.000000  \n",
      "mean    85074.155951  \n",
      "std      5712.913352  \n",
      "min     78961.000000  \n",
      "25%     78961.000000  \n",
      "50%     90413.000000  \n",
      "75%     90413.000000  \n",
      "max     90413.000000  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Historical'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDescriptive Statistics:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m.\u001b[39mdescribe())\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Correlation Matrix\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m corr_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCorrelation Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, corr_matrix)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Histograms\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\frame.py:11049\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[1;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[0;32m  11047\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m  11048\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m> 11049\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m  11051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  11052\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\frame.py:1993\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1992\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[1;32m-> 1993\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1694\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1692\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1693\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1694\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1753\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1752\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1753\u001b[0m     result[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1754\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Historical'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the cleaned and prepared data\n",
    "file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Prepared Data:\\n\", data.head())\n",
    "\n",
    "# Descriptive Statistics\n",
    "print(\"\\nDescriptive Statistics:\\n\", data.describe())\n",
    "\n",
    "# Correlation Matrix\n",
    "corr_matrix = data.corr()\n",
    "print(\"\\nCorrelation Matrix:\\n\", corr_matrix)\n",
    "\n",
    "# Visualization\n",
    "# Histograms\n",
    "data.hist(figsize=(15, 10))\n",
    "plt.suptitle('Histograms of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "sns.pairplot(data.select_dtypes(include=[np.number]))\n",
    "plt.suptitle('Scatter Plot of Numerical Features')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for detecting outliers in numerical columns\n",
    "plt.figure(figsize=(15, 10))\n",
    "data.select_dtypes(include=[np.number]).boxplot()\n",
    "plt.title('Boxplot of Numerical Features')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Distribution of categorical features\n",
    "categorical_columns = data.select_dtypes(include=[object]).columns\n",
    "for col in categorical_columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data[col])\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a09ae9-e09c-4ae9-b683-de9435926a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      6  Historical      115883       1.0        1.0             D   \n",
      "4      7  Historical      863939       1.0        1.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              4                 1        334011.0    100.00         2006   \n",
      "4              2                 1       1287938.0    121.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice  \n",
      "0          8         28.97        31.84  \n",
      "1         39          0.00        15.54  \n",
      "2         34         30.19        27.97  \n",
      "3         20        133.93        83.15  \n",
      "4         28          4.00        23.99  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_18716\\2824167599.py:14: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      8  Historical      214948       0.0        0.0             D   \n",
      "4      9  Historical      484059       0.0        0.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              0                 0       1783153.0    132.00         2011   \n",
      "4             13                 1       2314801.0     95.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice       date  daily_usage  month  \\\n",
      "0          8         28.97        31.84 2015-01-01     0.021918      1   \n",
      "1         39          0.00        15.54 2005-01-01     0.106849      1   \n",
      "2         34         30.19        27.97 2013-01-01     0.093151      1   \n",
      "3         33        138.98        13.64 2011-01-01     0.090411      1   \n",
      "4         33         90.77        46.49 2010-01-01     0.090411      1   \n",
      "\n",
      "   order_count  \n",
      "0        78961  \n",
      "1        78961  \n",
      "2        78961  \n",
      "3        78961  \n",
      "4        78961  \n",
      "Prepared data saved to C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Load data from the local CSV file\n",
    "file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\SalesKaggle3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Original Data:\\n\", data.head())\n",
    "\n",
    "# Data Cleaning\n",
    "# Handling missing values\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "data.dropna(inplace=True)  # Drop any remaining NaN values\n",
    "\n",
    "# Removing outliers (example using z-score method)\n",
    "z_scores = np.abs(stats.zscore(data.select_dtypes(include=[np.number])))\n",
    "data = data[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Feature Engineering\n",
    "# Example: Creating new features such as average daily usage, seasonal variations, and supplier reliability\n",
    "\n",
    "# Since we don't have dates, we'll create a dummy 'date' column based on 'ReleaseYear'\n",
    "data['date'] = pd.to_datetime(data['ReleaseYear'], format='%Y')\n",
    "\n",
    "# Average Daily Usage (dummy example since actual usage data isn't available)\n",
    "data['daily_usage'] = data['ItemCount'] / 365  # Assuming item count spread over a year\n",
    "\n",
    "# Seasonal Variations (Example: Extracting month as a feature)\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "# Supplier Reliability (Example: Counting orders per marketing type as a proxy)\n",
    "marketing_reliability = data.groupby('MarketingType')['Order'].count().reset_index()\n",
    "marketing_reliability.columns = ['MarketingType', 'order_count']\n",
    "data = pd.merge(data, marketing_reliability, on='MarketingType')\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "print(\"Prepared Data:\\n\", data.head())\n",
    "\n",
    "# Save the cleaned and prepared data to a new CSV file\n",
    "output_file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"Prepared data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289d0f2-fe53-4374-a6a0-bb061ec108b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
