{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f5b9855-4f77-4eed-87a4-6a2013e73fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      6  Historical      115883       1.0        1.0             D   \n",
      "4      7  Historical      863939       1.0        1.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              4                 1        334011.0    100.00         2006   \n",
      "4              2                 1       1287938.0    121.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice  \n",
      "0          8         28.97        31.84  \n",
      "1         39          0.00        15.54  \n",
      "2         34         30.19        27.97  \n",
      "3         20        133.93        83.15  \n",
      "4         28          4.00        23.99  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_28524\\902860707.py:13: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data \"0\" doesn't match format \"%Y\", at position 82. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Drop any remaining NaN values\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Feature Engineering\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Create a dummy 'date' column based on 'ReleaseYear'\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mReleaseYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Average Daily Usage (dummy example since actual usage data isn't available)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaily_usage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mItemCount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m365\u001b[39m  \u001b[38;5;66;03m# Assuming item count spread over a year\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[1;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:433\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;66;03m# `format` could be inferred, or user didn't ask for mixed-format parsing.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_array_strptime_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\learn-env3\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:467\u001b[0m, in \u001b[0;36m_array_strptime_with_fallback\u001b[1;34m(arg, name, utc, fmt, exact, errors)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_array_strptime_with_fallback\u001b[39m(\n\u001b[0;32m    457\u001b[0m     arg,\n\u001b[0;32m    458\u001b[0m     name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    463\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Index:\n\u001b[0;32m    464\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \u001b[38;5;124;03m    Call array_strptime, with fallback behavior depending on 'errors'.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 467\u001b[0m     result, tz_out \u001b[38;5;241m=\u001b[39m \u001b[43marray_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tz_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    469\u001b[0m         unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mstrptime.pyx:501\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:451\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime.array_strptime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mstrptime.pyx:583\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.strptime._parse_with_format\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: time data \"0\" doesn't match format \"%Y\", at position 82. You might want to try:\n    - passing `format` if your strings have a consistent format;\n    - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n    - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from the uploaded CSV file\n",
    "file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\SalesKaggle3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Original Data:\\n\", data.head())\n",
    "\n",
    "# Data Cleaning\n",
    "# Handling missing values\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "data.dropna(inplace=True)  # Drop any remaining NaN values\n",
    "\n",
    "# Feature Engineering\n",
    "# Create a dummy 'date' column based on 'ReleaseYear'\n",
    "data['date'] = pd.to_datetime(data['ReleaseYear'], format='%Y')\n",
    "\n",
    "# Average Daily Usage (dummy example since actual usage data isn't available)\n",
    "data['daily_usage'] = data['ItemCount'] / 365  # Assuming item count spread over a year\n",
    "\n",
    "# Seasonal Variations (Example: Extracting month as a feature)\n",
    "data['month'] = data['date'].dt.month\n",
    "\n",
    "# Supplier Reliability (Example: Counting orders per marketing type as a proxy)\n",
    "marketing_reliability = data.groupby('MarketingType')['Order'].count().reset_index()\n",
    "marketing_reliability.columns = ['MarketingType', 'order_count']\n",
    "data = pd.merge(data, marketing_reliability, on='MarketingType')\n",
    "\n",
    "# Display the first few rows of the prepared data\n",
    "print(\"Prepared Data:\\n\", data.head())\n",
    "\n",
    "# Save the cleaned and prepared data to a new CSV file\n",
    "output_file_path = '/mnt/data/prepared_sales_data.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"Prepared data saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "505a24c2-3e15-4afc-b454-b95a65067eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      6  Historical      115883       1.0        1.0             D   \n",
      "4      7  Historical      863939       1.0        1.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              4                 1        334011.0    100.00         2006   \n",
      "4              2                 1       1287938.0    121.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice  \n",
      "0          8         28.97        31.84  \n",
      "1         39          0.00        15.54  \n",
      "2         34         30.19        27.97  \n",
      "3         20        133.93        83.15  \n",
      "4         28          4.00        23.99  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data from the uploaded CSV file\n",
    "file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\SalesKaggle3.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the data\n",
    "print(\"Original Data:\\n\", data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "716dbfa0-7b6a-47b0-9c6f-5ba3d8c260b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_28524\\2179082341.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n"
     ]
    }
   ],
   "source": [
    "# Handling missing values\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "data.dropna(inplace=True)  # Drop any remaining NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16f5b5ae-5b5d-443c-b1b1-b6b4a17cb8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in ReleaseYear:\n",
      " [2015 2005 2013 2006 2010 2011 2008 2004 2007 2001 2012 2009 2003 2000\n",
      " 2002 2014 2016 2017 2018]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check unique values in 'ReleaseYear'\n",
    "unique_release_years = data['ReleaseYear'].unique()\n",
    "\n",
    "\n",
    "# Filter out products with a 'ReleaseYear' prior to 2000\n",
    "data = data[data['ReleaseYear'] >= 2000]\n",
    "print(\"Unique values in ReleaseYear:\\n\", unique_release_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5f39bb9-48e3-4910-a961-316a69db32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'ReleaseYear' to datetime\n",
    "data['date'] = pd.to_datetime(data['ReleaseYear'], format='%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070f44fc-93fc-4f1f-a397-ac2a0f84ecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_28524\\127281955.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['date'].fillna(pd.to_datetime(mode_year, format='%Y'), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle any conversion errors by filling them with a placeholder date (e.g., the mode year)\n",
    "mode_year = data['ReleaseYear'].mode()[0]\n",
    "data['date'].fillna(pd.to_datetime(mode_year, format='%Y'), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db49acf0-2f8d-4e6a-9b72-35689591f38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silve\\AppData\\Local\\Temp\\ipykernel_28524\\1776235960.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n"
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "# Handling missing values\n",
    "data.fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "data.dropna(inplace=True)  # Drop any remaining NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9375eda5-bc9f-4d43-83f9-f610ccb949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# Average Daily Usage (dummy example since actual usage data isn't available)\n",
    "data['daily_usage'] = data['ItemCount'] / 365  # Assuming item count spread over a year\n",
    "\n",
    "# Seasonal Variations (Example: Extracting month as a feature)\n",
    "data['month'] = data['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e415fb74-795c-45e6-b157-63615d6504a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Variations (Example: Extracting month as a feature)\n",
    "data['month'] = data['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "788f7e70-835a-4a9d-8a1a-501718ee641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supplier Reliability (Example: Counting orders per marketing type as a proxy)\n",
    "marketing_reliability = data.groupby('MarketingType')['Order'].count().reset_index()\n",
    "marketing_reliability.columns = ['MarketingType', 'order_count']\n",
    "data = pd.merge(data, marketing_reliability, on='MarketingType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d10d92a-ae72-4724-b56a-56ea279c52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared Data:\n",
      "    Order   File_Type  SKU_number  SoldFlag  SoldCount MarketingType  \\\n",
      "0      2  Historical     1737127       0.0        0.0             D   \n",
      "1      3  Historical     3255963       0.0        0.0             D   \n",
      "2      4  Historical      612701       0.0        0.0             D   \n",
      "3      6  Historical      115883       1.0        1.0             D   \n",
      "4      7  Historical      863939       1.0        1.0             D   \n",
      "\n",
      "   ReleaseNumber  New_Release_Flag  StrengthFactor  PriceReg  ReleaseYear  \\\n",
      "0             15                 1        682743.0     44.99         2015   \n",
      "1              7                 1       1016014.0     24.81         2005   \n",
      "2              0                 0        340464.0     46.00         2013   \n",
      "3              4                 1        334011.0    100.00         2006   \n",
      "4              2                 1       1287938.0    121.95         2010   \n",
      "\n",
      "   ItemCount  LowUserPrice  LowNetPrice       date  daily_usage  month  \\\n",
      "0          8         28.97        31.84 2015-01-01     0.021918      1   \n",
      "1         39          0.00        15.54 2005-01-01     0.106849      1   \n",
      "2         34         30.19        27.97 2013-01-01     0.093151      1   \n",
      "3         20        133.93        83.15 2006-01-01     0.054795      1   \n",
      "4         28          4.00        23.99 2010-01-01     0.076712      1   \n",
      "\n",
      "   order_count  \n",
      "0        82883  \n",
      "1        82883  \n",
      "2        82883  \n",
      "3        82883  \n",
      "4        82883  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the prepared data\n",
    "print(\"Prepared Data:\\n\", data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a401784-f11e-4e79-b5f2-a21da9cd594f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared data saved to C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "output_file_path = r'C:\\Users\\silve\\Downloads\\archive (6)\\prepared_sales_data.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"Prepared data saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0cbec8-be65-4724-b430-9a39e3efe795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
